{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# classification Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**YOUR NAME, YOUR SURNAME**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094e1c6",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| Python libraries contain previously combined set of codes that can be iteratively used, hence reducing time. As the term  suggests it’s similar to the physical library that holds reusable resources. However, in this instance it holds reusable lines of code that can be used in other programmes. In this project we used numpy, pandas, matplotlib, seaborn and sklearn libraries  for the purposes of data loading, manipulation, visualisation, preparation and model building. \n",
    "__1. Numpy:__\n",
    "Aids in mathematical ,numerical calculations and computations. It used in scientific, engineering, and data science programming. And is the most essential library for performing mathematical and statistical operations.\n",
    "__2. Pandas:__\n",
    "Provides us with vast facilities for data munipulation and analysis.\n",
    "__3. Matplotlib and seaborn:__\n",
    "These are both data visualisation libraries which provide functions to plot various data sets.\n",
    "__4. sklearn:__\n",
    "Is a software machine learning library which provides various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN. It is also designed to interoperate with numerical and scientific libraries such as, NumPy and SciPy|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "# Libraries for data preparation and model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import keras\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| Two main datasets will be used in this project.\n",
    "  **1. df_train_cvs loaded as df** \n",
    "  This dataframe will be used to train our model.\n",
    "  **2. df_test_cvs loaded as test_df**\n",
    "  test_df Will be used as our test data to assess the accurary of our model.|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, to gain a better understanding of the data, we did a basic analysis of the dataframe to get an overview of the contents in the table. Moreover, we performed various statistical analysis methods and visualiations to gauge two main things. firstly, the relationship between the target variable(load_shortfall_3h) and the independent variables. Secondly, the relationship between the independent variables themselves. This analysis will aid us in determining which independant variables are relevant and weather or not we should remove or engineer new variables. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fccfc644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f25cd1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     int64\n",
       "message      object\n",
       "tweetid       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the df datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65505f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the the df for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15819.000000</td>\n",
       "      <td>15819.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.917504</td>\n",
       "      <td>501719.433656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.836537</td>\n",
       "      <td>289045.983132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>253207.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>502291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>753769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>999888.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment        tweetid\n",
       "count  15819.000000   15819.000000\n",
       "mean       0.917504  501719.433656\n",
       "std        0.836537  289045.983132\n",
       "min       -1.000000       6.000000\n",
       "25%        1.000000  253207.500000\n",
       "50%        1.000000  502291.000000\n",
       "75%        1.000000  753769.000000\n",
       "max        2.000000  999888.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at the number summaries to try gather insight of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a004b4-9da7-48e4-82be-5c9f644a34ef",
   "metadata": {},
   "source": [
    "# Scatter Plots \n",
    "Here we plotted a few scatter plots for each city, showing the respective realtionships between the weather and load shortfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7884fc8a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47961257-6c2c-4d1d-83b3-3c5cc0919bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, we will clean the data and create new features which will aid in preparing the data for modeling.|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d9124-80d2-4bbe-a6ed-244665a68655",
   "metadata": {},
   "source": [
    "# Cleaning The Data for both Training and Testing sets\n",
    "- We filled missing values of valencia pressure with the median\n",
    "- We converted and normalised the Data for Valencia_wind_deg and Seville_pressure\n",
    "- We converted time to its proper datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the training Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00ef27-7226-49d0-8e56-c75cdd620887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Test Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51844238-a9ec-4a1a-8f6c-d04ae72b3480",
   "metadata": {},
   "source": [
    "# Gathered Insights\n",
    "- Time and day seem to be a big indicator of the load_shortfall so we will engineer new features to be used in our model.    \n",
    "- This graph also shows the High nature of the variance in the Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca73bf4-cf7f-4c93-9194-2b0cdc8597e2",
   "metadata": {},
   "source": [
    "# New Features\n",
    "- We created two new features called \"time of day\" and \"day\" which represent the the time of the day and the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51344e2-d430-4df2-afe6-8bad28a05e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ae4ec-4ea5-40bb-92f5-bb45db8da900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2af91780-e20d-451a-9df4-2fab81c17025",
   "metadata": {},
   "source": [
    "# Plotting New Feaures to veiw Relationships\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965969a8-cfd6-42dc-a5b6-0d14459700da",
   "metadata": {},
   "source": [
    "# Gathered Insights\n",
    "- Time of Day : Has a very clear relationship of increasing from 06H00 a.m till its peak around 21H00 and there after decreasing again till its minimum value at 06H00 again. After a bit of research we know that the coldest part of the day is just before sunrise, so perhaps the major contributer to Green Energy is Solar or Thermal in nature\n",
    "- Day - We see a very clear spike in load_shortfall after the first five days of the month, this could indicate that perhaps Spain imports a portion of their power and the budget is used very quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849dc3e-4c67-4766-a8e3-cd1494e38753",
   "metadata": {},
   "source": [
    "# Relevant Features\n",
    "- We will use all the independent features except temperature averages to create our model, The reason for excluding \n",
    "temperature averages is due to multicollinearity with the other temperature features(min/max) in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "|  To ensure we are getting the best possible predictions we will be using four regression models to compare the results. The overall idea of regression is to examine two things. Firstly, does a set of predictor variables do a good job in predicting an outcome (dependent) variable?. Secondly, which variables in particular are significant predictors of the outcome variable, and in what way do they–indicated by the magnitude and sign of the beta estimates–impact the outcome variable?  These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables.\n",
    "  Description of models: \n",
    "   1. Ridge: Is a technique for analyzing multiple regression data that suffers from multicollinearity.\n",
    "   2. Linear: Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. For example, a modeler might want to relate the weights of individuals to their heights using a linear regression model.\n",
    "   3. Random Forest: A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.\n",
    "   4. Decision tree: builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bad69d-6d4e-4983-9d36-0fcb99a548bb",
   "metadata": {},
   "source": [
    "# Predictor vs Target Variables\n",
    "- nw_df was set to conatin all relevant predictor variables from feature engineering\n",
    "- Target was set to load_shortfall_3h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d0d473-8d1d-4cc4-811c-9daddad1c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  df[\"message\"]\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1eadd37-7caa-4ec7-a27e-683896917873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Test Train split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c576ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(max_features= 10546 ,ngram_range=(1, 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6980be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_X_train=tfidf.fit_transform(X_train)\n",
    "tf_X_test=tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a698ed4-0239-4bc3-a840-ecb634e0504a",
   "metadata": {},
   "source": [
    "# Selection of Models\n",
    "- We decided to use a few different types of models for our data set and would be judging accuracy based on a MSE and RMSE \n",
    "## Models Used\n",
    "- Linear - Simple Regression model \n",
    "- Ridge - Regression model using stadardisation and scaliing\n",
    "- Random Forest - Regression model using random forking variables\n",
    "- Decision Tree - Regression model using forking variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f201979-8bce-419d-8c0a-91505b85ecd3",
   "metadata": {},
   "source": [
    "### Training and Fitting the data on our selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d462bf8e-b103-4f36-ab80-6961c94bd359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Support vector Machine Model\n",
    "sclf = svm.SVC(kernel='linear', C = 1.0)\n",
    "#clf=LinearSVC()\n",
    "sclf.fit(tf_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b81751-723d-4d93-962a-177ee09c7986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Random Forest Regression Model\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(tf_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b1d2738-c301-46ff-8763-2ebe89d4d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Decision Tree Regression Model\n",
    "dclf = DecisionTreeClassifier()\n",
    "dclf = dclf.fit(tf_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c9a09-1a68-460a-b4ac-584522cb565f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c290b1-e86f-46b8-8dcb-8e11b84eca2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6793976f-520d-42a0-a6cc-df8f29952cbd",
   "metadata": {},
   "source": [
    "# Creating Predictions on our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b6d4fe4-7491-4136-ac9e-a038c5e4330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for testing data\n",
    "Random_pred_forest=classifier .predict(tf_X_test)\n",
    "Svm_pred=clf .predict(tf_X_test)\n",
    "Decision_pred=dclf .predict(tf_X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4f846-7b4f-475b-890c-fa1eb0adca8a",
   "metadata": {},
   "source": [
    "# Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adee186-249d-467e-935b-d246d97b17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,Random_pred))\n",
    "print(classification_report(y_test,Svm_pred))\n",
    "print(classification_report(y_test,Decision_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc210b-71a0-4bfd-8392-a3a42b2fe188",
   "metadata": {},
   "source": [
    "# Final Model Creation and CSV export\n",
    "- using our svm Model we created our prediction for the Test Data set with the following predictor columns\n",
    "- dropped time from our test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad8add-8180-4dfa-aebd-58c6c384e0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5eaa12-5696-4bda-bf63-77f6cb2ece07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95796c3f-ccfd-4cf6-8aff-5162d5c1cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'time': test_df.time, 'load_shortfall_3h': predictions})\n",
    "submission.to_csv('rob2_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa811407-2131-4bd1-b7f6-f387c56e01a4",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "- Very low RMSE score of 3491, Random Forest was the best predictor of our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a923e3",
   "metadata": {},
   "source": [
    "# discuss chosen methods logic\n",
    "\n",
    "A random forest regression is an example of the ensemble idea applied to decision trees.\n",
    "\n",
    "In machine learning, one of the most widely used and highly effective methods involves creating learning models known as ensembles. An ensemble combines a variety of individual models to produce a more powerful overall model than each of the individual learning models.Why are ensembles effective? Well, one reason is that if we have different learning models, although each of them might perform well individually, they'll tend to make different kinds of mistakes on the data set. And typically, this happens because each individual model might overfit to a different part of the data. By combining different individual models into an ensemble, we can average out their individual mistakes to reduce the risk of overfitting while maintaining strong prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39ea76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
